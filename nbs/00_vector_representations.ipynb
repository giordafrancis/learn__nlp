{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e27ce2-ed87-499a-8963-c4531f297dd2",
   "metadata": {},
   "source": [
    "## Vector representation\n",
    "\n",
    "\n",
    "### Count Vectorizer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0aef9-65e5-424e-8841-150959212529",
   "metadata": {},
   "source": [
    "- Definition: Converts a collection of text documents to a matrix of token counts.\n",
    "- Purpose: To represent text data as numerical data for machine learning algorithms.\n",
    "\n",
    "How it works:\n",
    "- Each unique word in the corpus is assigned a unique integer index.\n",
    "- The output is a sparse matrix where each row represents a document and each column represents a word, with the value being the count of the word in that document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff2f0d-ea24-468a-b9f2-ff5b3e7a79b3",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "- Definition: Converts a collection of raw documents to a matrix of TF-IDF features.\n",
    "- Purpose: To reflect the importance of a word in a document relative to the entire corpus.\n",
    "- Components:\n",
    "  - Term Frequency (TF): The number of times a word appears in a document, divided by the total number of words in that document.\n",
    "  - Inverse Document Frequency (IDF): The logarithm of the total number of documents divided by the number of documents containing the word. This helps reduce the weight of common words.\n",
    "\n",
    "How it works:\n",
    "- Words that are frequent in a document but rare in the corpus get higher scores.\n",
    "- The output is a sparse matrix similar to Count Vectorizer but with TF-IDF scores instead of counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9fd6f5c-087d-4621-be0f-d72214aa806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/frangs/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/frangs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications.\",\n",
    "    \"A survey of user opinion of computer system response time.\",\n",
    "    \"The EPS user interface management system.\",\n",
    "    \"System and human system engineering testing of EPS.\",\n",
    "    \"Relation of user perceived response time to error measurement.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42373527-8a1a-4600-9dec-a9548e5fde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess all documents\n",
    "preprocessed_documents = [preprocess(doc) for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de670ddf-8dbf-45e4-920e-b26aac40be39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['human machin interfac lab abc comput applic',\n",
       " 'survey user opinion comput system respons time',\n",
       " 'ep user interfac manag system',\n",
       " 'system human system engin test ep',\n",
       " 'relat user perceiv respons time error measur']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e80f6f-35a1-49eb-82c2-2612ac70cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer Example\n",
    "count_vectorizer = CountVectorizer()\n",
    "X_counts = count_vectorizer.fit_transform(preprocessed_documents)\n",
    "\n",
    "# TF-IDF Example\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fefcbc8-0fed-40bb-ab7d-53b8297da75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer Matrix:\n",
      " [[1 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 1 1]\n",
      " [0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1]\n",
      " [0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 2 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 0 0 0 1 1]]\n",
      "TF-IDF Matrix:\n",
      " [[0.40986539 0.40986539 0.33067681 0.         0.         0.\n",
      "  0.33067681 0.33067681 0.40986539 0.40986539 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.36635462 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.45408711 0.         0.         0.36635462 0.45408711 0.30410743\n",
      "  0.         0.36635462 0.30410743]\n",
      " [0.         0.         0.         0.         0.45109178 0.\n",
      "  0.         0.45109178 0.         0.         0.55911663 0.\n",
      "  0.         0.         0.         0.         0.         0.37444693\n",
      "  0.         0.         0.37444693]\n",
      " [0.         0.         0.         0.44298611 0.3573984  0.\n",
      "  0.3573984  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.59334592\n",
      "  0.44298611 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.41701629\n",
      "  0.         0.         0.         0.         0.         0.41701629\n",
      "  0.         0.41701629 0.41701629 0.33644611 0.         0.\n",
      "  0.         0.33644611 0.27928067]]\n",
      "Count Vectorizer Feature Names:\n",
      " ['abc' 'applic' 'comput' 'engin' 'ep' 'error' 'human' 'interfac' 'lab'\n",
      " 'machin' 'manag' 'measur' 'opinion' 'perceiv' 'relat' 'respons' 'survey'\n",
      " 'system' 'test' 'time' 'user']\n",
      "TF-IDF Feature Names:\n",
      " ['abc' 'applic' 'comput' 'engin' 'ep' 'error' 'human' 'interfac' 'lab'\n",
      " 'machin' 'manag' 'measur' 'opinion' 'perceiv' 'relat' 'respons' 'survey'\n",
      " 'system' 'test' 'time' 'user']\n"
     ]
    }
   ],
   "source": [
    "# Display the vectorized data\n",
    "print(\"Count Vectorizer Matrix:\\n\", X_counts.toarray())\n",
    "print(\"TF-IDF Matrix:\\n\", X_tfidf.toarray())\n",
    "\n",
    "# Print the feature names (vocabulary)\n",
    "print(\"Count Vectorizer Feature Names:\\n\", count_vectorizer.get_feature_names_out())\n",
    "print(\"TF-IDF Feature Names:\\n\", tfidf_vectorizer.get_feature_names_out())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
