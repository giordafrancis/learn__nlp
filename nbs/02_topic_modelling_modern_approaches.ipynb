{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9ceeb7-baab-4ed2-a5f8-8b4919caa714",
   "metadata": {},
   "source": [
    "# Topic Modelling Modern Approaches\n",
    "\n",
    "> A further look at the role of Embeddings and Transformer approaches to Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da1b8b6-0fb0-40df-be71-3ea24b3d6b3a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Where Topic Modelling Fits in NLP and Machine Learning\n",
    "\n",
    "1. NLP Tasks: Topic modeling is part of unsupervised learning in NLP, often used for text mining, information retrieval, and content recommendation.\n",
    "2. Machine Learning: It utilizes unsupervised machine learning algorithms to discover hidden patterns in data without predefined labels or categories.\n",
    "\n",
    "Topic modelling is a technique in natural language processing (NLP) used to uncover the underlying topics that are present in a collection of documents. It helps in identifying patterns and organizing large sets of textual data by clustering similar words and phrases into topics. This technique is particularly useful for summarizing, categorizing, and analyzing text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e9b23-9bf3-42ef-84b1-2fed8ea1fd5b",
   "metadata": {},
   "source": [
    "## Code samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bdd49f-b0a5-44ce-ba1f-08dd93927134",
   "metadata": {},
   "source": [
    "### Example of a simple document term matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a0c60f-849a-4302-903e-0ba7a69b9e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 0 1 1]\n",
      " [0 1 0 0 1 1 1 0 1]\n",
      " [0 0 1 0 0 0 0 0 1]\n",
      " [0 1 0 1 0 1 0 0 1]]\n",
      "['brown' 'dog' 'fox' 'is' 'jumps' 'lazy' 'over' 'quick' 'the']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The quick brown fox\",\n",
    "    \"jumps over the lazy dog\",\n",
    "    \"The fox\",\n",
    "    \"The dog is lazy\"\n",
    "]\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array and print\n",
    "print(X.toarray())\n",
    "\n",
    "# Feature names (vocabulary)\n",
    "print(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5c994-0837-4eb3-9840-c9897c8254c6",
   "metadata": {},
   "source": [
    "## Term Embedding\n",
    "\n",
    "Embeddings are dense vector representations of words or phrases that capture semantic meanings. Unlike sparse representations like one-hot encoding, embeddings map words to continuous vector spaces where semantically similar words have similar representations. These vectors are typically of lower dimensions (e.g., 100-300 dimensions) compared to the vocabulary size.\n",
    "\n",
    "\n",
    "### Importance of Embeddings\n",
    "\n",
    "1. Semantic Similarity: Words with similar meanings are closer in the embedding space.\n",
    "2. Dimensionality Reduction: Embeddings reduce the dimensionality of text data while preserving meaningful relationships.\n",
    "3. Improved Performance: Embeddings improve the performance of NLP models by providing more informative features compared to traditional methods.\n",
    "\n",
    "\n",
    "### Popular Embedding Strategies\n",
    "\n",
    "1. Word2Vec: Predicts a word given its context (Skip-gram) or predicts the context given a word (CBOW).\n",
    "2. GloVe (Global Vectors for Word Representation): Uses co-occurrence statistics to learn word embeddings.\n",
    "3. FastText: Extends Word2Vec by considering subword information, which helps with out-of-vocabulary words.\n",
    "4. BERT (Bidirectional Encoder Representations from Transformers): Uses transformer-based architecture to create context-aware embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494858f3-2740-42cc-b5fd-c2bb0bd197d0",
   "metadata": {},
   "source": [
    "## Implementation Example: Word2Vec with Gensim\n",
    "\n",
    "### Code Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55bfbceb-6afe-4fd5-a27c-9a4bfef9b537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00515774 -0.00667028 -0.0077791   0.00831315 -0.00198292 -0.00685696\n",
      " -0.0041556   0.00514562 -0.00286997 -0.00375075  0.0016219  -0.0027771\n",
      " -0.00158482  0.0010748  -0.00297881  0.00852176  0.00391207 -0.00996176\n",
      "  0.00626142 -0.00675622  0.00076966  0.00440552 -0.00510486 -0.00211128\n",
      "  0.00809783 -0.00424503 -0.00763848  0.00926061 -0.00215612 -0.00472081\n",
      "  0.00857329  0.00428459  0.0043261   0.00928722 -0.00845554  0.00525685\n",
      "  0.00203994  0.0041895   0.00169839  0.00446543  0.0044876   0.0061063\n",
      " -0.00320303 -0.00457706 -0.00042664  0.00253447 -0.00326412  0.00605948\n",
      "  0.00415534  0.00776685  0.00257002  0.00811905 -0.00138761  0.00808028\n",
      "  0.0037181  -0.00804967 -0.00393476 -0.0024726   0.00489447 -0.00087241\n",
      " -0.00283173  0.00783599  0.00932561 -0.0016154  -0.00516075 -0.00470313\n",
      " -0.00484746 -0.00960562  0.00137242 -0.00422615  0.00252744  0.00561612\n",
      " -0.00406709 -0.00959937  0.00154715 -0.00670207  0.0024959  -0.00378173\n",
      "  0.00708048  0.00064041  0.00356198 -0.00273993 -0.00171105  0.00765502\n",
      "  0.00140809 -0.00585215 -0.00783678  0.00123305  0.00645651  0.00555797\n",
      " -0.00897966  0.00859466  0.00404816  0.00747178  0.00974917 -0.0072917\n",
      " -0.00904259  0.0058377   0.00939395  0.00350795]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.test.utils import common_texts  # Example dataset\n",
    "\n",
    "# Tokenize and preprocess the text\n",
    "sentences = [simple_preprocess(\" \".join(doc)) for doc in common_texts]\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"word2vec.model\")\n",
    "\n",
    "# Load the model\n",
    "model = Word2Vec.load(\"word2vec.model\")\n",
    "\n",
    "# Get the vector for a specific word\n",
    "vector = model.wv['computer']\n",
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd8324f4-a5ca-4fa5-b645-5bbc970303ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'computer',\n",
       "  'eps',\n",
       "  'graph',\n",
       "  'human',\n",
       "  'interface',\n",
       "  'minors',\n",
       "  'response',\n",
       "  'survey',\n",
       "  'system',\n",
       "  'time',\n",
       "  'trees',\n",
       "  'user'},\n",
       " 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uwords = set(w for doc in common_texts for w in doc)\n",
    "uwords, len(uwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf4c149-5006-4fea-a92d-d49e05760356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyedVectors<vector_size=100, 12 keys>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.wv)\n",
    "len(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11951578-6d00-44fe-b46f-dd37019f0c45",
   "metadata": {},
   "source": [
    "## Implementation using BerTopic\n",
    "\n",
    "BerTopic docs are a great reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c27a7e-227a-41e9-b9d7-6c59b9fd66c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3602</td>\n",
       "      <td>-1_the_and_to_of</td>\n",
       "      <td>[the, and, to, of, for, in, is, from, on, it]</td>\n",
       "      <td>[From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>486</td>\n",
       "      <td>0_he_year_baseball_game</td>\n",
       "      <td>[he, year, baseball, game, runs, team, pitchin...</td>\n",
       "      <td>[From: mse@cc.bellcore.com (25836-michael even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "      <td>1_gun_guns_firearms_weapons</td>\n",
       "      <td>[gun, guns, firearms, weapons, militia, amendm...</td>\n",
       "      <td>[From: PA146008@utkvm1.utk.edu (David Veal)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>2_clipper_encryption_chip_key</td>\n",
       "      <td>[clipper, encryption, chip, key, keys, escrow,...</td>\n",
       "      <td>[Subject: text of White House announcement and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>246</td>\n",
       "      <td>3_car_cars_saturn_dealer</td>\n",
       "      <td>[car, cars, saturn, dealer, engine, toyota, fo...</td>\n",
       "      <td>[From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0     -1   3602               -1_the_and_to_of   \n",
       "1      0    486        0_he_year_baseball_game   \n",
       "2      1    332    1_gun_guns_firearms_weapons   \n",
       "3      2    310  2_clipper_encryption_chip_key   \n",
       "4      3    246       3_car_cars_saturn_dealer   \n",
       "\n",
       "                                      Representation  \\\n",
       "0      [the, and, to, of, for, in, is, from, on, it]   \n",
       "1  [he, year, baseball, game, runs, team, pitchin...   \n",
       "2  [gun, guns, firearms, weapons, militia, amendm...   \n",
       "3  [clipper, encryption, chip, key, keys, escrow,...   \n",
       "4  [car, cars, saturn, dealer, engine, toyota, fo...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...  \n",
       "1  [From: mse@cc.bellcore.com (25836-michael even...  \n",
       "2  [From: PA146008@utkvm1.utk.edu (David Veal)\\nS...  \n",
       "3  [Subject: text of White House announcement and...  \n",
       "4  [From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\n...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bertopic import BERTopic\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# Load dataset\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "docs = newsgroups_train.data\n",
    "\n",
    "# Initialise BERTopic\n",
    "topic_model = BERTopic()\n",
    "\n",
    "# Fit the model\n",
    "model_path = Path(\"bertopic_model.pkl\")\n",
    "if not model_path.exists():\n",
    "    topics, _ = topic_model.fit_transform(docs)\n",
    "    with open(model_path, 'wb') as file:\n",
    "        pickle.dump(topic_model, file)\n",
    "else:\n",
    "    # Save the model\n",
    "    with open(model_path, 'rb') as file:\n",
    "        topic_model  = pickle.load(file)\n",
    "# Get the topics\n",
    "topic_model.get_topic_info().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eabb346-0f80-4477-92b8-33b629de038b",
   "metadata": {},
   "source": [
    "We can extract info  at a document level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2398d61e-ac79-4a55-9dc3-e13cc6b80ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>3</td>\n",
       "      <td>3_car_cars_saturn_dealer</td>\n",
       "      <td>[car, cars, saturn, dealer, engine, toyota, fo...</td>\n",
       "      <td>[From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\n...</td>\n",
       "      <td>car - cars - saturn - dealer - engine - toyota...</td>\n",
       "      <td>0.766315</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>148</td>\n",
       "      <td>148_iisi_clock_kuo_mhz</td>\n",
       "      <td>[iisi, clock, kuo, mhz, cpu, si, speed, guykuo...</td>\n",
       "      <td>[From: durtralp@ux1.isu.edu (Ralph Durtschi)\\n...</td>\n",
       "      <td>iisi - clock - kuo - mhz - cpu - si - speed - ...</td>\n",
       "      <td>0.711629</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_the_and_to_of</td>\n",
       "      <td>[the, and, to, of, for, in, is, from, on, it]</td>\n",
       "      <td>[From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...</td>\n",
       "      <td>the - and - to - of - for - in - is - from - o...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_the_and_to_of</td>\n",
       "      <td>[the, and, to, of, for, in, is, from, on, it]</td>\n",
       "      <td>[From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...</td>\n",
       "      <td>the - and - to - of - for - in - is - from - o...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_the_and_to_of</td>\n",
       "      <td>[the, and, to, of, for, in, is, from, on, it]</td>\n",
       "      <td>[From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...</td>\n",
       "      <td>the - and - to - of - for - in - is - from - o...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...      3   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...    148   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...     -1   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...     -1   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...     -1   \n",
       "\n",
       "                       Name  \\\n",
       "0  3_car_cars_saturn_dealer   \n",
       "1    148_iisi_clock_kuo_mhz   \n",
       "2          -1_the_and_to_of   \n",
       "3          -1_the_and_to_of   \n",
       "4          -1_the_and_to_of   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [car, cars, saturn, dealer, engine, toyota, fo...   \n",
       "1  [iisi, clock, kuo, mhz, cpu, si, speed, guykuo...   \n",
       "2      [the, and, to, of, for, in, is, from, on, it]   \n",
       "3      [the, and, to, of, for, in, is, from, on, it]   \n",
       "4      [the, and, to, of, for, in, is, from, on, it]   \n",
       "\n",
       "                                 Representative_Docs  \\\n",
       "0  [From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\n...   \n",
       "1  [From: durtralp@ux1.isu.edu (Ralph Durtschi)\\n...   \n",
       "2  [From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...   \n",
       "3  [From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...   \n",
       "4  [From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...   \n",
       "\n",
       "                                         Top_n_words  Probability  \\\n",
       "0  car - cars - saturn - dealer - engine - toyota...     0.766315   \n",
       "1  iisi - clock - kuo - mhz - cpu - si - speed - ...     0.711629   \n",
       "2  the - and - to - of - for - in - is - from - o...     0.000000   \n",
       "3  the - and - to - of - for - in - is - from - o...     0.000000   \n",
       "4  the - and - to - of - for - in - is - from - o...     0.000000   \n",
       "\n",
       "   Representative_document  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per document info\n",
    "topic_model.get_document_info(docs).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7511912-cd4b-4c94-9558-a22c00462b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# topic_model.get_topic_info???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc4d1dc8-f4f4-4e2c-8fb5-a9ac44fef590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>3602</td>\n",
       "      <td>-1_the_and_to_of</td>\n",
       "      <td>[the, and, to, of, for, in, is, from, on, it]</td>\n",
       "      <td>[From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>486</td>\n",
       "      <td>0_he_year_baseball_game</td>\n",
       "      <td>[he, year, baseball, game, runs, team, pitchin...</td>\n",
       "      <td>[From: mse@cc.bellcore.com (25836-michael even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>332</td>\n",
       "      <td>1_gun_guns_firearms_weapons</td>\n",
       "      <td>[gun, guns, firearms, weapons, militia, amendm...</td>\n",
       "      <td>[From: PA146008@utkvm1.utk.edu (David Veal)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>310</td>\n",
       "      <td>2_clipper_encryption_chip_key</td>\n",
       "      <td>[clipper, encryption, chip, key, keys, escrow,...</td>\n",
       "      <td>[Subject: text of White House announcement and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>246</td>\n",
       "      <td>3_car_cars_saturn_dealer</td>\n",
       "      <td>[car, cars, saturn, dealer, engine, toyota, fo...</td>\n",
       "      <td>[From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                           Name  \\\n",
       "0     -1   3602               -1_the_and_to_of   \n",
       "1      0    486        0_he_year_baseball_game   \n",
       "2      1    332    1_gun_guns_firearms_weapons   \n",
       "3      2    310  2_clipper_encryption_chip_key   \n",
       "4      3    246       3_car_cars_saturn_dealer   \n",
       "\n",
       "                                      Representation  \\\n",
       "0      [the, and, to, of, for, in, is, from, on, it]   \n",
       "1  [he, year, baseball, game, runs, team, pitchin...   \n",
       "2  [gun, guns, firearms, weapons, militia, amendm...   \n",
       "3  [clipper, encryption, chip, key, keys, escrow,...   \n",
       "4  [car, cars, saturn, dealer, engine, toyota, fo...   \n",
       "\n",
       "                                 Representative_Docs  \n",
       "0  [From: tgl+@cs.cmu.edu (Tom Lane)\\nSubject: JP...  \n",
       "1  [From: mse@cc.bellcore.com (25836-michael even...  \n",
       "2  [From: PA146008@utkvm1.utk.edu (David Veal)\\nS...  \n",
       "3  [Subject: text of White House announcement and...  \n",
       "4  [From: CPKJP@vm.cc.latech.edu (Kevin Parker)\\n...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df = topic_model.get_topic_info()\n",
    "row = topic_df.sample(1)\n",
    "topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d0559bc-0709-40a3-a5fc-93d49ddbb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 51, 27, 185, 212]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('car', 0.021168209993219375),\n",
       " ('cars', 0.012855802188158174),\n",
       " ('saturn', 0.008281874562218591),\n",
       " ('dealer', 0.00795250455143509),\n",
       " ('engine', 0.00746471868549103),\n",
       " ('toyota', 0.006062030111426506),\n",
       " ('ford', 0.005955146329301384),\n",
       " ('honda', 0.005829464376667094),\n",
       " ('price', 0.005762489694584342),\n",
       " ('integra', 0.005270325883958921)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_topics, similarity = topic_model.find_topics(\"car\", top_n=5)\n",
    "print(similar_topics)\n",
    "topic_model.get_topic(similar_topics[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
