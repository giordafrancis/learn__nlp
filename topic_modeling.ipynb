{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b9ceeb7-baab-4ed2-a5f8-8b4919caa714",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab46f726-329e-41a4-9d5a-22cbfcb8654c",
   "metadata": {},
   "source": [
    "## Where Topic Modelling Fits in NLP and Machine Learning\n",
    "\n",
    "1. NLP Tasks: Topic modeling is part of unsupervised learning in NLP, often used for text mining, information retrieval, and content recommendation.\n",
    "2. Machine Learning: It utilizes unsupervised machine learning algorithms to discover hidden patterns in data without predefined labels or categories.\n",
    "\n",
    "Topic modelling is a technique in natural language processing (NLP) used to uncover the underlying topics that are present in a collection of documents. It helps in identifying patterns and organizing large sets of textual data by clustering similar words and phrases into topics. This technique is particularly useful for summarizing, categorizing, and analyzing text data.\n",
    "\n",
    "## Bag of Words (BoW) Model\n",
    "\n",
    "- Definition: The Bag of Words model is a simplifying representation used in natural language processing (NLP). **In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and word order but keeping multiplicity.**\n",
    "- Feature Extraction: Texts are converted into fixed-length vectors. Common techniques include simple word counts, term frequency (TF), and term frequency-inverse document frequency (TF-IDF). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9982601-9d4a-46bc-9fed-79baf340f5e4",
   "metadata": {},
   "source": [
    "LSA (Latent Semantic Analysis), NMF (Non-negative Matrix Factorization), and LDA (Latent Dirichlet Allocation) are considered \"bag of words\" models. Why:?    \n",
    "\n",
    "- Input Representation: All three models (LSA, NMF, LDA) take a document-term matrix as input, which is constructed using the bag of words approach.\n",
    "- Word Order Ignored: The inherent characteristic of BoW models is that they do not consider the order of words. All three models operate on this premise.\n",
    "- Focus on Frequency/Presence: They focus on the frequency or presence of words in documents, which is a key aspect of the bag of words approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4820e53-13b3-45e8-940c-6e702a3e03eb",
   "metadata": {},
   "source": [
    "## Common Algorithms for Topic Modeling\n",
    "\n",
    "1. Latent Dirichlet Allocation (LDA): One of the most popular methods, which assumes that each document is a mixture of a small number of topics and that each word in the document is attributable to one of the document's topics. Probabilistic Model: LDA is a generative probabilistic model that assumes documents are mixtures of topics, and topics are mixtures of word\n",
    "2. Non-negative Matrix Factorization (NMF): A linear algebra approach that factorizes the term-document matrix into non-negative matrices.\n",
    "3. Latent Semantic Analysis (LSA): A technique that applies singular value decomposition (SVD) to the term-document matrix to reduce its dimensions and uncover the latent structure in the data.\n",
    "\n",
    "**Summary of Why They Are BoW Model**\n",
    "\n",
    "1. Input Representation: All three models (LSA, NMF, LDA) take a document-term matrix (eg CountVectorizer, TfIDF sparse matrices) as input, which is constructed using the bag of words approach.\n",
    "2. Word Order Ignored: The inherent characteristic of BoW models is that they do not consider the order of words. All three models operate on this premise.\n",
    "3. Focus on Frequency/Presence: They focus on the frequency or presence of words in documents, which is a key aspect of the bag of words approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004e9b23-9bf3-42ef-84b1-2fed8ea1fd5b",
   "metadata": {},
   "source": [
    "## Code samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bdd49f-b0a5-44ce-ba1f-08dd93927134",
   "metadata": {},
   "source": [
    "### Example of a simple document term matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39a0c60f-849a-4302-903e-0ba7a69b9e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 0 1 1]\n",
      " [0 1 0 0 1 1 1 0 1]\n",
      " [0 0 1 0 0 0 0 0 1]\n",
      " [0 1 0 1 0 1 0 0 1]]\n",
      "['brown' 'dog' 'fox' 'is' 'jumps' 'lazy' 'over' 'quick' 'the']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The quick brown fox\",\n",
    "    \"jumps over the lazy dog\",\n",
    "    \"The fox\",\n",
    "    \"The dog is lazy\"\n",
    "]\n",
    "\n",
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to array and print\n",
    "print(X.toarray())\n",
    "\n",
    "# Feature names (vocabulary)\n",
    "print(vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27569df6-b45a-4021-94af-1bed96c7253a",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f98969-8e79-443c-b0d2-3dcb66f9cdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: machin, abc, applic, measur, perceiv, error, relat, manag, user, interfac\n",
      "\n",
      "Topic: 1 \n",
      "Words: comput, respons, time, user, engin, test, survey, opinion, ep, system\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\"\n",
    "]\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess all documents\n",
    "preprocessed_documents = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Vectorize the documents using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(preprocessed_documents)\n",
    "\n",
    "# Train the LDA model\n",
    "lda = LatentDirichletAllocation(n_components=2, random_state=0)\n",
    "lda.fit(X_tfidf)\n",
    "\n",
    "# Print the topics\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic: {idx} \\nWords: {', '.join([tfidf_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07533c-ebe5-4b5d-9df2-f21ddc95da78",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "014aa281-63be-4284-9280-619b88c4d8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: lab, machin, user, engin, test, human, manag, interfac, ep, system\n",
      "\n",
      "Topic: 1 \n",
      "Words: comput, opinion, survey, measur, perceiv, relat, error, user, time, respons\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NMF\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\"\n",
    "]\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess all documents\n",
    "preprocessed_documents = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Vectorize the documents using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(preprocessed_documents)\n",
    "\n",
    "# Train the NMF model\n",
    "nmf = NMF(n_components=2, random_state=0)\n",
    "nmf.fit(X_tfidf)\n",
    "\n",
    "# Print the topics\n",
    "for idx, topic in enumerate(nmf.components_):\n",
    "    print(f\"Topic: {idx} \\nWords: {', '.join([tfidf_vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-10:]])}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d47278-490e-4fb4-8234-a7d9e75cd68a",
   "metadata": {},
   "source": [
    "### LSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1c3bb7-ec55-41c7-9c0d-9820b988aa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "opinion human comput time respons manag interfac ep user system \n",
      "\n",
      "Topic 1:\n",
      "comput opinion survey user measur perceiv relat error time respons \n",
      "\n",
      "Word-Topic Matrix (first 10 terms):\n",
      " [[ 0.09173987  0.09173987  0.21909378  0.16600004  0.32477867  0.10543331\n",
      "   0.20794293  0.26486604  0.09173987  0.09173987]\n",
      " [-0.1077054  -0.1077054   0.05139182 -0.17741717 -0.25731592  0.27463756\n",
      "  -0.23003509 -0.2010729  -0.1077054  -0.1077054 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/frangs/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/frangs/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# LSA\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"Human machine interface for lab abc computer applications.\",\n",
    "    \"A survey of user opinion of computer system response time.\",\n",
    "    \"The EPS user interface management system.\",\n",
    "    \"System and human system engineering testing of EPS.\",\n",
    "    \"Relation of user perceived response time to error measurement.\"\n",
    "]\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Preprocess all documents\n",
    "preprocessed_documents = [preprocess(doc) for doc in documents]\n",
    "# Vectorize the preprocessed documents using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(preprocessed_documents)\n",
    "\n",
    "# Apply Truncated SVD (LSA)\n",
    "lsa = TruncatedSVD(n_components=2, random_state=0)\n",
    "X_lsa = lsa.fit_transform(X_tfidf)\n",
    "\n",
    "# Print the topics\n",
    "terms = tfidf_vectorizer.get_feature_names_out()\n",
    "for idx, component in enumerate(lsa.components_):\n",
    "    print(f\"Topic {idx}:\")\n",
    "    for i in component.argsort()[-10:]:\n",
    "        print(f\"{terms[i]}\", end=' ')\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Print word-topic matrix to show embeddings of terms\n",
    "print(\"Word-Topic Matrix (first 10 terms):\\n\", lsa.components_[:, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c53f95-0791-443b-84ba-fef5c2e301ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68b4549-d681-4cbe-beed-7dca8f215f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad14a8b-8c27-4912-b670-9082408942dd",
   "metadata": {},
   "source": [
    "## Metrics and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e6b52-a961-4bf4-920c-1ff32a5501bd",
   "metadata": {},
   "source": [
    "### Topic coherence\n",
    "\n",
    "Topic Coherence refers to the degree to which the words within a single topic are semantically related to each other. It helps evaluate how interpretable the topics generated by a model are. A high coherence score generally indicates that the topics are meaningful and make sense to humans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d906b1f-8670-4a60-91fa-3a8452bdbfc2",
   "metadata": {},
   "source": [
    "#### Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961fbcdf-733c-4a18-b611-8cc2a5ff7377",
   "metadata": {},
   "source": [
    "##### Perplexity\n",
    "\n",
    "   \n",
    "1. Definition: Perplexity is a measure of how well a probabilistic model predicts a sample of unseen data. In the context of topic modeling, perplexity evaluates how well the model predicts the words in unseen documents given the learned topics.\n",
    "\n",
    "Intuition behind Perplexity:\n",
    "\n",
    "- Model Prediction: The perplexity metric quantifies how surprised a model is by new unseen data.\n",
    "- Word Prediction: Lower perplexity means the model is less surprised by new documents and can predict the words more accurately.\n",
    "\n",
    "\n",
    "2. Calculation\n",
    "   $$\\text{Perplexity} = \\exp\\left(-\\frac{1}{N} \\sum \\log p(w_i)\\right)$$\n",
    "\n",
    "Where:\n",
    "\n",
    "    - N is the total number of words in the test set.\n",
    "    - p(wi) is the probability assigned by the model to word wi\n",
    "   \n",
    "\n",
    "For a given test set of documents, perplexity is calculated using the probabilities assigned to the words in the documents by the topic model.\n",
    "\n",
    "3. Interpretation of Perplexity\n",
    "\n",
    "- Lower Perplexity: Indicates better model performance. The model is less surprised by the test data and can predict the words more accurately.\n",
    "- Higher Perplexity: Indicates poorer model performance. The model struggles to predict the words in the test data accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23aebd8-488f-4205-a24c-ab6f6d655d3b",
   "metadata": {},
   "source": [
    "##### Coherence Score:\n",
    "\n",
    "1. Definition: The coherence score measures the degree of semantic similarity between high scoring words in the topics.\n",
    "2. Importance: It aligns more closely with human judgment compared to perplexity.\n",
    "3. Common Implementations: Tools like Gensim provide functions to compute coherence scores for LDA models.\n",
    "\n",
    "##### Human Interpretability\n",
    "\n",
    "1. Definition: Evaluating how understandable and meaningful the topics are to human users.\n",
    "2. Methods:\n",
    "   - Human Judgment: Experts or annotators assess the quality of the topics by checking if the top words in each topic form a coherent and interpretable set.\n",
    "   - Qualitative Analysis: Reviewing the most representative documents for each topic to see if they align with the expected topic themes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b6ab15-e376-42a1-9eba-5c48d4a5aa1c",
   "metadata": {},
   "source": [
    "### Code samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f4996f-06f6-4e3c-8396-fd400e5d877f",
   "metadata": {},
   "source": [
    "##### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afff543e-ae3d-4958-a5d6-f6c9046bf8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 24.072064586265917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The dog barks loudly\",\n",
    "    \"The cat meows softly\",\n",
    "    \"The dog and cat are pets\",\n",
    "    \"The quick brown fox jumps over the lazy dog\",\n",
    "    \"Never jump over the lazy dog quickly\"\n",
    "]\n",
    "\n",
    "# Preprocessing and Vectorization\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Train LDA model\n",
    "lda = LatentDirichletAllocation(n_components=2, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Calculate Perplexity on the same data (usually you use a held-out test set)\n",
    "perplexity = lda.perplexity(X)\n",
    "\n",
    "print(f'Perplexity: {perplexity}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97183942-fb52-4796-8fc5-c6f0063edafc",
   "metadata": {},
   "source": [
    "##### Coherence score \n",
    "\n",
    "using gensim, unable to figure out a sklearn version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f803ee46-2e74-4cde-9682-db2e034effd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.29927940849732204\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    [\"dog\", \"barks\", \"loudly\"],\n",
    "    [\"cat\", \"meows\", \"softly\"],\n",
    "    [\"dog\", \"and\", \"cat\", \"are\", \"pets\"]\n",
    "]\n",
    "\n",
    "# Create a dictionary and corpus\n",
    "dictionary = Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in documents]\n",
    "\n",
    "# Train LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=2, random_state=42)\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=documents, dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model_lda.get_coherence()\n",
    "\n",
    "print(f'Coherence Score: {coherence_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "751e58c4-68fa-4add-b960-4c7b1b83716e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 13.519769559569319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"The dog barks loudly\",\n",
    "    \"The cat meows softly\",\n",
    "    \"The dog and cat are pets\"\n",
    "]\n",
    "\n",
    "# Preprocessing and Vectorization\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Train LDA model\n",
    "lda = LatentDirichletAllocation(n_components=2, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Calculate Perplexity on the same data (usually you use a held-out test set)\n",
    "perplexity = lda.perplexity(X)\n",
    "\n",
    "print(f'Perplexity: {perplexity}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c0bc69-aaf3-4990-bd41-1f694d2d70c3",
   "metadata": {},
   "source": [
    "## Term Embeddings in Topic Analysis BoW\n",
    "\n",
    "Term embeddings are dense vector representations of words that capture semantic meanings. They are not inherently part of the traditional algorithms like LDA, NMF, and LSA. However, embeddings can be used in conjunction with these algorithms to enhance their performance. For instance:\n",
    "\n",
    "1. LDA and NMF: Typically do not use term embeddings directly. They work with the term-document matrix (from Count Vectorizer or TF-IDF).\n",
    "2. LSA: Can be considered a precursor to modern embedding techniques. It reduces the dimensionality of the term-document matrix, uncovering latent semantic structures, but does not produce embeddings in the modern sense (like Word2Vec or GloVe).\n",
    "\n",
    "### LSA and Embeddings\n",
    "\n",
    "#### LSA (Latent Semantic Analysis):\n",
    "- *Reduction to Latent Space:* LSA uses Singular Value Decomposition (SVD) to reduce the high-dimensional term-document matrix to a lower-dimensional space. This reduced space can be seen as capturing latent semantic structures.\n",
    "\n",
    "- *Document-Topic and Word-Topic Matrices:* In LSA, the matrices obtained from SVD can be viewed as embeddings in a reduced semantic space. For instance, the X_lsa matrix represents documents in terms of latent topics, while the other matrices (U, Σ, and V^T from SVD) represent relationships between terms and topics.\n",
    "\n",
    "- *Similarity to Embeddings:* The key similarity is that **both embeddings and LSA capture semantic relationships and reduce dimensionality. However, LSA’s vectors are derived from linear algebra rather than neural network-based optimization.**\n",
    "\n",
    "#### Why NMF and LDA Aren't Typically Considered Embeddings\n",
    "\n",
    "##### NMF (Non-negative Matrix Factorization):\n",
    "- *Matrix Factorization:* NMF factorizes the term-document matrix into two lower-dimensional matrices (document-topic and topic-word) with non-negative constraints. These matrices can be interpreted similarly to embeddings, but they are not typically referred to as embeddings because they are not trained in the same way as traditional embeddings.\n",
    "- *Interpretability:* NMF’s components are directly interpretable as topics, which is different from the general-purpose semantic vectors produced by embeddings.\n",
    "\n",
    "##### LDA (Latent Dirichlet Allocation):\n",
    "\n",
    "- Probabilistic Model: LDA is a generative probabilistic model that assumes documents are mixtures of topics, and topics are mixtures of words. It outputs distributions over topics for each document and distributions over words for each topic.\n",
    "- Distributional Output: The outputs (document-topic and topic-word distributions) can be high-dimensional and sparse, contrasting with the dense, fixed-length vectors of embeddings.\n",
    "- Interpretability: Like NMF, LDA’s outputs are highly interpretable in terms of topics but don’t function as general-purpose semantic embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
